{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/bin/python3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import socket\n",
    "import glob\n",
    "\n",
    "import os\n",
    "import sys\n",
    " \n",
    "import provider\n",
    "import tf_util\n",
    "from model import *\n",
    "print(\"success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12\n",
    "BATCH_SIZE_EVAL = 12\n",
    "NUM_POINT = 4096\n",
    "MAX_EPOCH = 61\n",
    "BASE_LEARNING_RATE = 0.001\n",
    "GPU_INDEX = 0\n",
    "MOMENTUM = 0.9\n",
    "OPTIMIZER = 'adam'\n",
    "DECAY_STEP = 300000\n",
    "DECAY_RATE = 0.5\n",
    "\n",
    "LOG_DIR = 'log'\n",
    "if not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)\n",
    "os.system('cp model.py %s' % (LOG_DIR)) # bkp of model def\n",
    "#os.system('cp train.py %s' % (LOG_DIR)) # bkp of train procedure\n",
    "LOG_FOUT = open(os.path.join(LOG_DIR, 'log_train.txt'), 'w')\n",
    "# LOG_FOUT.write(str(FLAGS)+'\\n')\n",
    "\n",
    "MAX_NUM_POINT = 4096\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "BN_INIT_DECAY = 0.5\n",
    "BN_DECAY_DECAY_RATE = 0.5\n",
    "#BN_DECAY_DECAY_STEP = float(DECAY_STEP * 2)\n",
    "BN_DECAY_DECAY_STEP = float(DECAY_STEP)\n",
    "BN_DECAY_CLIP = 0.99\n",
    "\n",
    "HOSTNAME = socket.gethostname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 4096, 6)\n",
      "(360, 4096)\n"
     ]
    }
   ],
   "source": [
    "#Normalize data\n",
    "xmax = 3.0\n",
    "xmin = -3.0\n",
    "\n",
    "DATASET_DIR = 'data/'\n",
    "f = h5py.File(DATASET_DIR+ 'd0.h5','r')\n",
    "NUM_FRAMES = f['data'].shape[0]\n",
    "\n",
    "total_data = np.zeros((6*NUM_FRAMES,4096, 6))\n",
    "total_label = np.zeros((6*NUM_FRAMES,4096))\n",
    "\n",
    "for i in range (0,6):\n",
    "    f = h5py.File(DATASET_DIR+ 'd' +str(i)+'.h5','r')\n",
    "    data = f['data']\n",
    "    label = f['label']\n",
    "    total_data[i*len(data):(i+1)*len(data),:,0:3] = (data[:, :, 0:3] - xmin) / (xmax  - xmin )\n",
    "    total_data[i*len(data):(i+1)*len(data),:,3:6] = data[:, :, 3:6]\n",
    "    total_label[i*len(data):(i+1)*len(data),:] = label[:, :]\n",
    "    \n",
    "print(total_data.shape)\n",
    "print(total_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_range : 0.29408538341522217 0.7170508503913879\n",
      "y_range : 0.317680299282074 0.6883880098660787\n",
      "z_range : 0.5334503278136253 0.8151378035545349\n",
      "r_range : 0.0 0.004490316845476627\n",
      "g_range : 1.5118113878997974e-05 0.004506220109760761\n",
      "b_range : 0.0 0.004490316845476627\n"
     ]
    }
   ],
   "source": [
    "features = [\"x\",\"y\",\"z\",\"r\",\"g\",\"b\"]\n",
    "for i in range(6): \n",
    "    print(features[i] + \"_range :\", np.min(total_data[:, :, i]), np.max(total_data[:, :, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 4096, 6), (360, 4096))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = total_data\n",
    "y = total_label\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_range : 0.29408538341522217 0.7170508503913879\n",
      "y_range : 0.317680299282074 0.6883880098660787\n",
      "z_range : 0.5334503278136253 0.8151378035545349\n",
      "r_range : 0.0 0.004490316845476627\n",
      "g_range : 1.5118113878997974e-05 0.004506220109760761\n",
      "b_range : 0.0 0.004490316845476627\n"
     ]
    }
   ],
   "source": [
    "features = [\"x\",\"y\",\"z\",\"r\",\"g\",\"b\"]\n",
    "for i in range(6): \n",
    "    print(features[i] + \"_range :\", np.min(total_data[:, :, i]), np.max(total_data[:, :, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(324, 4096, 6) (324, 4096)\n",
      "(36, 4096, 6) (36, 4096)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_label, test_label = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "print(train_data.shape, train_label.shape)\n",
    "print(test_data.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/atas/PointNet_Custom_Object_Detection/model.py:13: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/atas/PointNet_Custom_Object_Detection/tf_util.py:145: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/atas/PointNet_Custom_Object_Detection/tf_util.py:21: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/atas/PointNet_Custom_Object_Detection/tf_util.py:48: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/atas/PointNet_Custom_Object_Detection/tf_util.py:368: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Tensor(\"fc2/Relu:0\", shape=(12, 128), dtype=float32, device=/device:GPU:0)\n",
      "WARNING:tensorflow:From /home/atas/PointNet_Custom_Object_Detection/tf_util.py:573: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-18-454625cf90e3>:44: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "**** EPOCH 000 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 1.008698\n",
      "accuracy: 0.798151\n",
      "----\n",
      "eval mean loss: 0.241924\n",
      "eval accuracy: 0.906982\n",
      "eval avg class acc: 0.756513\n",
      "Model saved in file: log/model.ckpt\n",
      "**** EPOCH 001 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.196723\n",
      "accuracy: 0.922791\n",
      "----\n",
      "eval mean loss: 0.151227\n",
      "eval accuracy: 0.932712\n",
      "eval avg class acc: 0.846656\n",
      "**** EPOCH 002 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.151396\n",
      "accuracy: 0.930599\n",
      "----\n",
      "eval mean loss: 0.127655\n",
      "eval accuracy: 0.948398\n",
      "eval avg class acc: 0.914894\n",
      "**** EPOCH 003 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.139446\n",
      "accuracy: 0.935631\n",
      "----\n",
      "eval mean loss: 0.132146\n",
      "eval accuracy: 0.940301\n",
      "eval avg class acc: 0.914151\n",
      "**** EPOCH 004 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.123951\n",
      "accuracy: 0.944995\n",
      "----\n",
      "eval mean loss: 0.115000\n",
      "eval accuracy: 0.946337\n",
      "eval avg class acc: 0.896373\n",
      "**** EPOCH 005 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.121624\n",
      "accuracy: 0.944778\n",
      "----\n",
      "eval mean loss: 0.112655\n",
      "eval accuracy: 0.947652\n",
      "eval avg class acc: 0.906350\n",
      "**** EPOCH 006 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.118246\n",
      "accuracy: 0.946349\n",
      "----\n",
      "eval mean loss: 0.119781\n",
      "eval accuracy: 0.946472\n",
      "eval avg class acc: 0.929025\n",
      "**** EPOCH 007 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.116957\n",
      "accuracy: 0.947982\n",
      "----\n",
      "eval mean loss: 0.101364\n",
      "eval accuracy: 0.950738\n",
      "eval avg class acc: 0.897353\n",
      "**** EPOCH 008 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.112406\n",
      "accuracy: 0.949845\n",
      "----\n",
      "eval mean loss: 0.111203\n",
      "eval accuracy: 0.952691\n",
      "eval avg class acc: 0.936622\n",
      "**** EPOCH 009 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.103808\n",
      "accuracy: 0.954343\n",
      "----\n",
      "eval mean loss: 0.100497\n",
      "eval accuracy: 0.955112\n",
      "eval avg class acc: 0.899416\n",
      "**** EPOCH 010 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.095821\n",
      "accuracy: 0.958387\n",
      "----\n",
      "eval mean loss: 0.097812\n",
      "eval accuracy: 0.957825\n",
      "eval avg class acc: 0.907302\n",
      "Model saved in file: log/model.ckpt\n",
      "**** EPOCH 011 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.091096\n",
      "accuracy: 0.960236\n",
      "----\n",
      "eval mean loss: 0.085231\n",
      "eval accuracy: 0.966397\n",
      "eval avg class acc: 0.958879\n",
      "**** EPOCH 012 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.088611\n",
      "accuracy: 0.962732\n",
      "----\n",
      "eval mean loss: 0.096151\n",
      "eval accuracy: 0.962518\n",
      "eval avg class acc: 0.928067\n",
      "**** EPOCH 013 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.084911\n",
      "accuracy: 0.964765\n",
      "----\n",
      "eval mean loss: 0.081937\n",
      "eval accuracy: 0.963806\n",
      "eval avg class acc: 0.936221\n",
      "**** EPOCH 014 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.081621\n",
      "accuracy: 0.966228\n",
      "----\n",
      "eval mean loss: 0.096337\n",
      "eval accuracy: 0.953762\n",
      "eval avg class acc: 0.889164\n",
      "**** EPOCH 015 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.080292\n",
      "accuracy: 0.965410\n",
      "----\n",
      "eval mean loss: 0.073854\n",
      "eval accuracy: 0.968479\n",
      "eval avg class acc: 0.960272\n",
      "**** EPOCH 016 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.074793\n",
      "accuracy: 0.969794\n",
      "----\n",
      "eval mean loss: 0.081202\n",
      "eval accuracy: 0.964227\n",
      "eval avg class acc: 0.956297\n",
      "**** EPOCH 017 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.073734\n",
      "accuracy: 0.969082\n",
      "----\n",
      "eval mean loss: 0.066039\n",
      "eval accuracy: 0.974691\n",
      "eval avg class acc: 0.966962\n",
      "**** EPOCH 018 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.066962\n",
      "accuracy: 0.972808\n",
      "----\n",
      "eval mean loss: 0.085164\n",
      "eval accuracy: 0.967109\n",
      "eval avg class acc: 0.951010\n",
      "**** EPOCH 019 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.073402\n",
      "accuracy: 0.970074\n",
      "----\n",
      "eval mean loss: 0.084970\n",
      "eval accuracy: 0.959262\n",
      "eval avg class acc: 0.898247\n",
      "**** EPOCH 020 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.067707\n",
      "accuracy: 0.972393\n",
      "----\n",
      "eval mean loss: 0.087726\n",
      "eval accuracy: 0.964613\n",
      "eval avg class acc: 0.927562\n",
      "Model saved in file: log/model.ckpt\n",
      "**** EPOCH 021 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.067118\n",
      "accuracy: 0.973566\n",
      "----\n",
      "eval mean loss: 0.070398\n",
      "eval accuracy: 0.970330\n",
      "eval avg class acc: 0.936143\n",
      "**** EPOCH 022 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.060460\n",
      "accuracy: 0.975642\n",
      "----\n",
      "eval mean loss: 0.069827\n",
      "eval accuracy: 0.969977\n",
      "eval avg class acc: 0.924864\n",
      "**** EPOCH 023 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.056692\n",
      "accuracy: 0.976703\n",
      "----\n",
      "eval mean loss: 0.063073\n",
      "eval accuracy: 0.971144\n",
      "eval avg class acc: 0.947633\n",
      "**** EPOCH 024 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.055752\n",
      "accuracy: 0.977225\n",
      "----\n",
      "eval mean loss: 0.061139\n",
      "eval accuracy: 0.973782\n",
      "eval avg class acc: 0.942242\n",
      "**** EPOCH 025 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.064802\n",
      "accuracy: 0.973611\n",
      "----\n",
      "eval mean loss: 0.087491\n",
      "eval accuracy: 0.959622\n",
      "eval avg class acc: 0.945362\n",
      "**** EPOCH 026 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.062257\n",
      "accuracy: 0.974967\n",
      "----\n",
      "eval mean loss: 0.059791\n",
      "eval accuracy: 0.972161\n",
      "eval avg class acc: 0.954922\n",
      "**** EPOCH 027 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.054938\n",
      "accuracy: 0.978553\n",
      "----\n",
      "eval mean loss: 0.066648\n",
      "eval accuracy: 0.968248\n",
      "eval avg class acc: 0.946727\n",
      "**** EPOCH 028 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.055953\n",
      "accuracy: 0.977178\n",
      "----\n",
      "eval mean loss: 0.064330\n",
      "eval accuracy: 0.968262\n",
      "eval avg class acc: 0.944418\n",
      "**** EPOCH 029 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.049490\n",
      "accuracy: 0.980509\n",
      "----\n",
      "eval mean loss: 0.069628\n",
      "eval accuracy: 0.974440\n",
      "eval avg class acc: 0.961259\n",
      "**** EPOCH 030 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.055429\n",
      "accuracy: 0.977953\n",
      "----\n",
      "eval mean loss: 0.068302\n",
      "eval accuracy: 0.973694\n",
      "eval avg class acc: 0.956013\n",
      "Model saved in file: log/model.ckpt\n",
      "**** EPOCH 031 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.050740\n",
      "accuracy: 0.979748\n",
      "----\n",
      "eval mean loss: 0.060194\n",
      "eval accuracy: 0.975884\n",
      "eval avg class acc: 0.957587\n",
      "**** EPOCH 032 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.042275\n",
      "accuracy: 0.983201\n",
      "----\n",
      "eval mean loss: 0.066811\n",
      "eval accuracy: 0.971944\n",
      "eval avg class acc: 0.935436\n",
      "**** EPOCH 033 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.044772\n",
      "accuracy: 0.982634\n",
      "----\n",
      "eval mean loss: 0.070046\n",
      "eval accuracy: 0.971680\n",
      "eval avg class acc: 0.940210\n",
      "**** EPOCH 034 ****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.045039\n",
      "accuracy: 0.982717\n",
      "----\n",
      "eval mean loss: 0.058332\n",
      "eval accuracy: 0.975511\n",
      "eval avg class acc: 0.938893\n",
      "**** EPOCH 035 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.054089\n",
      "accuracy: 0.977731\n",
      "----\n",
      "eval mean loss: 0.063767\n",
      "eval accuracy: 0.973755\n",
      "eval avg class acc: 0.945073\n",
      "**** EPOCH 036 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.052845\n",
      "accuracy: 0.979102\n",
      "----\n",
      "eval mean loss: 0.055141\n",
      "eval accuracy: 0.975525\n",
      "eval avg class acc: 0.969903\n",
      "**** EPOCH 037 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.044473\n",
      "accuracy: 0.982811\n",
      "----\n",
      "eval mean loss: 0.064377\n",
      "eval accuracy: 0.971524\n",
      "eval avg class acc: 0.957181\n",
      "**** EPOCH 038 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.042684\n",
      "accuracy: 0.984068\n",
      "----\n",
      "eval mean loss: 0.103064\n",
      "eval accuracy: 0.954454\n",
      "eval avg class acc: 0.866224\n",
      "**** EPOCH 039 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.048192\n",
      "accuracy: 0.981149\n",
      "----\n",
      "eval mean loss: 0.074258\n",
      "eval accuracy: 0.978651\n",
      "eval avg class acc: 0.977658\n",
      "**** EPOCH 040 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.071862\n",
      "accuracy: 0.972845\n",
      "----\n",
      "eval mean loss: 0.094167\n",
      "eval accuracy: 0.959913\n",
      "eval avg class acc: 0.952482\n",
      "Model saved in file: log/model.ckpt\n",
      "**** EPOCH 041 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.059988\n",
      "accuracy: 0.975794\n",
      "----\n",
      "eval mean loss: 0.055542\n",
      "eval accuracy: 0.975274\n",
      "eval avg class acc: 0.960077\n",
      "**** EPOCH 042 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.054544\n",
      "accuracy: 0.977881\n",
      "----\n",
      "eval mean loss: 0.075689\n",
      "eval accuracy: 0.964613\n",
      "eval avg class acc: 0.954147\n",
      "**** EPOCH 043 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.048926\n",
      "accuracy: 0.981060\n",
      "----\n",
      "eval mean loss: 0.059609\n",
      "eval accuracy: 0.973660\n",
      "eval avg class acc: 0.942426\n",
      "**** EPOCH 044 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.046545\n",
      "accuracy: 0.982130\n",
      "----\n",
      "eval mean loss: 0.053364\n",
      "eval accuracy: 0.977153\n",
      "eval avg class acc: 0.963196\n",
      "**** EPOCH 045 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.042898\n",
      "accuracy: 0.983765\n",
      "----\n",
      "eval mean loss: 0.062029\n",
      "eval accuracy: 0.977770\n",
      "eval avg class acc: 0.959650\n",
      "**** EPOCH 046 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.045164\n",
      "accuracy: 0.982276\n",
      "----\n",
      "eval mean loss: 0.085421\n",
      "eval accuracy: 0.966458\n",
      "eval avg class acc: 0.955027\n",
      "**** EPOCH 047 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.040232\n",
      "accuracy: 0.984698\n",
      "----\n",
      "eval mean loss: 0.048470\n",
      "eval accuracy: 0.977844\n",
      "eval avg class acc: 0.953725\n",
      "**** EPOCH 048 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.048771\n",
      "accuracy: 0.981206\n",
      "----\n",
      "eval mean loss: 0.065677\n",
      "eval accuracy: 0.971307\n",
      "eval avg class acc: 0.954560\n",
      "**** EPOCH 049 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.041173\n",
      "accuracy: 0.984381\n",
      "----\n",
      "eval mean loss: 0.059134\n",
      "eval accuracy: 0.974243\n",
      "eval avg class acc: 0.957041\n",
      "**** EPOCH 050 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.035652\n",
      "accuracy: 0.986528\n",
      "----\n",
      "eval mean loss: 0.063584\n",
      "eval accuracy: 0.977722\n",
      "eval avg class acc: 0.951847\n",
      "Model saved in file: log/model.ckpt\n",
      "**** EPOCH 051 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.036441\n",
      "accuracy: 0.986070\n",
      "----\n",
      "eval mean loss: 0.049376\n",
      "eval accuracy: 0.978563\n",
      "eval avg class acc: 0.953752\n",
      "**** EPOCH 052 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.034965\n",
      "accuracy: 0.986558\n",
      "----\n",
      "eval mean loss: 0.048546\n",
      "eval accuracy: 0.980001\n",
      "eval avg class acc: 0.965959\n",
      "**** EPOCH 053 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.038585\n",
      "accuracy: 0.984933\n",
      "----\n",
      "eval mean loss: 0.052392\n",
      "eval accuracy: 0.977132\n",
      "eval avg class acc: 0.962831\n",
      "**** EPOCH 054 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.035665\n",
      "accuracy: 0.986379\n",
      "----\n",
      "eval mean loss: 0.061242\n",
      "eval accuracy: 0.975206\n",
      "eval avg class acc: 0.956955\n",
      "**** EPOCH 055 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.038974\n",
      "accuracy: 0.985008\n",
      "----\n",
      "eval mean loss: 0.070987\n",
      "eval accuracy: 0.973192\n",
      "eval avg class acc: 0.928095\n",
      "**** EPOCH 056 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.035473\n",
      "accuracy: 0.986984\n",
      "----\n",
      "eval mean loss: 0.055677\n",
      "eval accuracy: 0.977397\n",
      "eval avg class acc: 0.948731\n",
      "**** EPOCH 057 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.032561\n",
      "accuracy: 0.987560\n",
      "----\n",
      "eval mean loss: 0.049144\n",
      "eval accuracy: 0.977627\n",
      "eval avg class acc: 0.953127\n",
      "**** EPOCH 058 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.036031\n",
      "accuracy: 0.986097\n",
      "----\n",
      "eval mean loss: 0.059511\n",
      "eval accuracy: 0.975586\n",
      "eval avg class acc: 0.943590\n",
      "**** EPOCH 059 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.029827\n",
      "accuracy: 0.988988\n",
      "----\n",
      "eval mean loss: 0.060700\n",
      "eval accuracy: 0.979167\n",
      "eval avg class acc: 0.957874\n",
      "**** EPOCH 060 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.026345\n",
      "accuracy: 0.990200\n",
      "----\n",
      "eval mean loss: 0.053610\n",
      "eval accuracy: 0.978963\n",
      "eval avg class acc: 0.956970\n",
      "Model saved in file: log/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def log_string(out_str):\n",
    "    LOG_FOUT.write(out_str+'\\n')\n",
    "    LOG_FOUT.flush()\n",
    "    print(out_str)\n",
    "\n",
    "\n",
    "def get_learning_rate(batch):\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "                        BASE_LEARNING_RATE,  # Base learning rate.\n",
    "                        batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "                        DECAY_STEP,          # Decay step.\n",
    "                        DECAY_RATE,          # Decay rate.\n",
    "                        staircase=True)\n",
    "    learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!!\n",
    "    return learning_rate        \n",
    "\n",
    "def get_bn_decay(batch):\n",
    "    bn_momentum = tf.train.exponential_decay(\n",
    "                      BN_INIT_DECAY,\n",
    "                      batch*BATCH_SIZE,\n",
    "                      BN_DECAY_DECAY_STEP,\n",
    "                      BN_DECAY_DECAY_RATE,\n",
    "                      staircase=True)\n",
    "    bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n",
    "    return bn_decay\n",
    "\n",
    "def train():\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.device('/gpu:'+str(GPU_INDEX)):\n",
    "            pointclouds_pl, labels_pl = placeholder_inputs(BATCH_SIZE, NUM_POINT)\n",
    "            is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "            \n",
    "            # Note the global_step=batch parameter to minimize. \n",
    "            # That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.\n",
    "            batch = tf.Variable(0)\n",
    "            bn_decay = get_bn_decay(batch)\n",
    "            tf.summary.scalar('bn_decay', bn_decay)\n",
    "\n",
    "            # Get model and loss \n",
    "            pred = get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay)\n",
    "            loss = get_loss(pred, labels_pl)\n",
    "            tf.summary.scalar('loss', loss)\n",
    "\n",
    "            correct = tf.equal(tf.argmax(pred, 2), tf.to_int64(labels_pl))\n",
    "            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE*NUM_POINT)\n",
    "            tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "            # Get training operator\n",
    "            learning_rate = get_learning_rate(batch)\n",
    "            tf.summary.scalar('learning_rate', learning_rate)\n",
    "            if OPTIMIZER == 'momentum':\n",
    "                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n",
    "            elif OPTIMIZER == 'adam':\n",
    "                optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            train_op = optimizer.minimize(loss, global_step=batch)\n",
    "            \n",
    "            # Add ops to save and restore all the variables.\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "        # Create a session\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        config.allow_soft_placement = True\n",
    "        config.log_device_placement = True\n",
    "        sess = tf.Session(config=config)\n",
    "\n",
    "        # Add summary writers\n",
    "        merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'train'),\n",
    "                                  sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'test'))\n",
    "\n",
    "        # Init variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init, {is_training_pl:True})\n",
    "\n",
    "        ops = {'pointclouds_pl': pointclouds_pl,\n",
    "               'labels_pl': labels_pl,\n",
    "               'is_training_pl': is_training_pl,\n",
    "               'pred': pred,\n",
    "               'loss': loss,\n",
    "               'train_op': train_op,\n",
    "               'merged': merged,\n",
    "               'step': batch}\n",
    "\n",
    "        for epoch in range(MAX_EPOCH):\n",
    "            log_string('**** EPOCH %03d ****' % (epoch))\n",
    "            sys.stdout.flush()\n",
    "             \n",
    "            train_one_epoch(sess, ops, train_writer)\n",
    "            eval_one_epoch(sess, ops, test_writer)\n",
    "            \n",
    "            # Save the variables to disk.\n",
    "            if epoch % 10 == 0:\n",
    "                save_path = saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"))\n",
    "                log_string(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(sess, ops, train_writer):\n",
    "    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n",
    "    is_training = True\n",
    "    \n",
    "    log_string('----')\n",
    "    current_data, current_label, _ = provider.shuffle_data(train_data[:,0:NUM_POINT,:], train_label) \n",
    "    \n",
    "    file_size = current_data.shape[0]\n",
    "    num_batches = file_size // BATCH_SIZE\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_seen = 0\n",
    "    loss_sum = 0\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Current batch/total batch num: %d/%d'%(batch_idx,num_batches))\n",
    "        start_idx = batch_idx * BATCH_SIZE\n",
    "        end_idx = (batch_idx+1) * BATCH_SIZE\n",
    "        \n",
    "        feed_dict = {ops['pointclouds_pl']: current_data[start_idx:end_idx, :, :],\n",
    "                     ops['labels_pl']: current_label[start_idx:end_idx],\n",
    "                     ops['is_training_pl']: is_training,}\n",
    "        summary, step, _, loss_val, pred_val = sess.run([ops['merged'], ops['step'], ops['train_op'], ops['loss'], ops['pred']],\n",
    "                                         feed_dict=feed_dict)\n",
    "        train_writer.add_summary(summary, step)\n",
    "        pred_val = np.argmax(pred_val, 2)\n",
    "        correct = np.sum(pred_val == current_label[start_idx:end_idx])\n",
    "        total_correct += correct\n",
    "        total_seen += (BATCH_SIZE*NUM_POINT)\n",
    "        loss_sum += loss_val\n",
    "    \n",
    "    log_string('mean loss: %f' % (loss_sum / float(num_batches)))\n",
    "    log_string('accuracy: %f' % (total_correct / float(total_seen)))\n",
    "\n",
    "        \n",
    "def eval_one_epoch(sess, ops, test_writer):\n",
    "    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n",
    "    is_training = False\n",
    "    total_correct = 0\n",
    "    total_seen = 0\n",
    "    loss_sum = 0\n",
    "    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
    "    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "    \n",
    "    log_string('----')\n",
    "    current_data = test_data[:,0:NUM_POINT,:]\n",
    "    current_label = np.squeeze(test_label)\n",
    "    \n",
    "    file_size = current_data.shape[0]\n",
    "    num_batches = file_size // BATCH_SIZE_EVAL\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * BATCH_SIZE_EVAL\n",
    "        end_idx = (batch_idx+1) * BATCH_SIZE_EVAL\n",
    "\n",
    "        feed_dict = {ops['pointclouds_pl']: current_data[start_idx:end_idx, :, :],\n",
    "                     ops['labels_pl']: current_label[start_idx:end_idx],\n",
    "                     ops['is_training_pl']: is_training}\n",
    "        summary, step, loss_val, pred_val = sess.run([ops['merged'], ops['step'], ops['loss'], ops['pred']],\n",
    "                                      feed_dict=feed_dict)\n",
    "        test_writer.add_summary(summary, step)\n",
    "        pred_val = np.argmax(pred_val, 2)\n",
    "        correct = np.sum(pred_val == current_label[start_idx:end_idx])\n",
    "        total_correct += correct\n",
    "        total_seen += (BATCH_SIZE_EVAL*NUM_POINT)\n",
    "        loss_sum += (loss_val*BATCH_SIZE_EVAL)\n",
    "        for i in range(start_idx, end_idx):\n",
    "            for j in range(NUM_POINT):\n",
    "                l = int(current_label[i, j])\n",
    "                total_seen_class[l] += 1\n",
    "                total_correct_class[l] += (pred_val[i-start_idx, j] == l)\n",
    "            \n",
    "    log_string('eval mean loss: %f' % (loss_sum / float(total_seen/NUM_POINT)))\n",
    "    log_string('eval accuracy: %f'% (total_correct / float(total_seen)))\n",
    "    log_string('eval avg class acc: %f' % (np.mean(np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float))))\n",
    "         \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n",
    "    LOG_FOUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
