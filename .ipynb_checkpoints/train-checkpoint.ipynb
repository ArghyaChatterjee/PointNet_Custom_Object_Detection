{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/bin/python3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import socket\n",
    "import glob\n",
    "\n",
    "import os\n",
    "import sys\n",
    " \n",
    "import provider\n",
    "import tf_util\n",
    "from model import *\n",
    "print(\"success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12\n",
    "BATCH_SIZE_EVAL = 12\n",
    "NUM_POINT = 4096\n",
    "MAX_EPOCH = 61\n",
    "BASE_LEARNING_RATE = 0.001\n",
    "GPU_INDEX = 0\n",
    "MOMENTUM = 0.9\n",
    "OPTIMIZER = 'adam'\n",
    "DECAY_STEP = 300000\n",
    "DECAY_RATE = 0.5\n",
    "\n",
    "LOG_DIR = 'log'\n",
    "if not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)\n",
    "os.system('cp model.py %s' % (LOG_DIR)) # bkp of model def\n",
    "os.system('cp train.py %s' % (LOG_DIR)) # bkp of train procedure\n",
    "LOG_FOUT = open(os.path.join(LOG_DIR, 'log_train.txt'), 'w')\n",
    "# LOG_FOUT.write(str(FLAGS)+'\\n')\n",
    "\n",
    "MAX_NUM_POINT = 4096\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "BN_INIT_DECAY = 0.5\n",
    "BN_DECAY_DECAY_RATE = 0.5\n",
    "#BN_DECAY_DECAY_STEP = float(DECAY_STEP * 2)\n",
    "BN_DECAY_DECAY_STEP = float(DECAY_STEP)\n",
    "BN_DECAY_CLIP = 0.99\n",
    "\n",
    "HOSTNAME = socket.gethostname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1158, 4096, 6)\n",
      "(1158, 4096)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xmax = 3.0\n",
    "xmin = -3.0\n",
    "DATASET_DIR = '/home/atas/FULL_H5_DATA/''\n",
    "NUM_FRAMES = 60\n",
    "total_data = np.zeros((6*NUM_FRAMES,4096, 6))\n",
    "total_label = np.zeros((6*NUM_FRAMES,4096))\n",
    "\n",
    "for i in range (0,6):\n",
    "    f = h5py.File(DATASET_DIR+ 'd' +str(i)+'.h5','r')\n",
    "    data = f['data']\n",
    "    label = f['label']\n",
    "    total_data[i*len(data):(i+1)*len(data),:,0:3] = (data[:, :, 0:3] - xmin) / (xmax  - xmin )\n",
    "    total_data[i*len(data):(i+1)*len(data),:,3:6] = data[:, :, 3:6]/255\n",
    "    total_label[i*len(data):(i+1)*len(data),:] = label[:, :]\n",
    "    \n",
    "print(total_data.shape)\n",
    "print(total_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_range : 0.27024004856745404 0.7425641020139059\n",
      "y_range : 0.30058085918426514 0.7210604945818583\n",
      "z_range : 0.5301859254638354 0.9228959878285726\n",
      "r_range : 0.0 0.004496253238004797\n",
      "g_range : 1.3209388171340904e-05 0.004500191819434072\n",
      "b_range : 0.0 0.004500191819434072\n"
     ]
    }
   ],
   "source": [
    "features = [\"x\",\"y\",\"z\",\"r\",\"g\",\"b\"]\n",
    "for i in range(6): \n",
    "    print(features[i] + \"_range :\", np.min(total_data[:, :, i]), np.max(total_data[:, :, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1158, 4096, 6), (1158, 4096))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = total_data\n",
    "y = total_label\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_range : 0.27024004856745404 0.7425641020139059\n",
      "y_range : 0.30058085918426514 0.7210604945818583\n",
      "z_range : 0.5301859254638354 0.9228959878285726\n",
      "r_range : 0.0 0.004496253238004797\n",
      "g_range : 1.3209388171340904e-05 0.004500191819434072\n",
      "b_range : 0.0 0.004500191819434072\n"
     ]
    }
   ],
   "source": [
    "features = [\"x\",\"y\",\"z\",\"r\",\"g\",\"b\"]\n",
    "for i in range(6): \n",
    "    print(features[i] + \"_range :\", np.min(total_data[:, :, i]), np.max(total_data[:, :, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1042, 4096, 6) (1042, 4096)\n",
      "(116, 4096, 6) (116, 4096)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_label, test_label = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "print(train_data.shape, train_label.shape)\n",
    "print(test_data.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/atas/PointNet-SemSeg-VKITTI3D/model.py:13: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/atas/PointNet-SemSeg-VKITTI3D/tf_util.py:145: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/atas/PointNet-SemSeg-VKITTI3D/tf_util.py:21: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/atas/PointNet-SemSeg-VKITTI3D/tf_util.py:48: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/atas/PointNet-SemSeg-VKITTI3D/tf_util.py:368: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Tensor(\"fc2/Relu:0\", shape=(12, 128), dtype=float32, device=/device:GPU:0)\n",
      "WARNING:tensorflow:From /home/atas/PointNet-SemSeg-VKITTI3D/tf_util.py:573: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-10-454625cf90e3>:44: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "**** EPOCH 000 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.489253\n",
      "accuracy: 0.837147\n",
      "----\n",
      "eval mean loss: 0.262097\n",
      "eval accuracy: 0.879571\n",
      "eval avg class acc: 0.815351\n",
      "Model saved in file: log/model.ckpt\n",
      "**** EPOCH 001 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.228337\n",
      "accuracy: 0.897861\n",
      "----\n",
      "eval mean loss: 0.217545\n",
      "eval accuracy: 0.903741\n",
      "eval avg class acc: 0.896178\n",
      "**** EPOCH 002 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.212480\n",
      "accuracy: 0.902517\n",
      "----\n",
      "eval mean loss: 0.196438\n",
      "eval accuracy: 0.908402\n",
      "eval avg class acc: 0.878860\n",
      "**** EPOCH 003 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.190283\n",
      "accuracy: 0.914244\n",
      "----\n",
      "eval mean loss: 0.180663\n",
      "eval accuracy: 0.915584\n",
      "eval avg class acc: 0.913420\n",
      "**** EPOCH 004 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.183468\n",
      "accuracy: 0.920302\n",
      "----\n",
      "eval mean loss: 0.170058\n",
      "eval accuracy: 0.922291\n",
      "eval avg class acc: 0.911378\n",
      "**** EPOCH 005 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.170043\n",
      "accuracy: 0.925107\n",
      "----\n",
      "eval mean loss: 0.153842\n",
      "eval accuracy: 0.932057\n",
      "eval avg class acc: 0.923809\n",
      "**** EPOCH 006 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.162043\n",
      "accuracy: 0.930096\n",
      "----\n",
      "eval mean loss: 0.150507\n",
      "eval accuracy: 0.933641\n",
      "eval avg class acc: 0.918398\n",
      "**** EPOCH 007 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.148646\n",
      "accuracy: 0.936249\n",
      "----\n",
      "eval mean loss: 0.146605\n",
      "eval accuracy: 0.934916\n",
      "eval avg class acc: 0.929662\n",
      "**** EPOCH 008 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.145822\n",
      "accuracy: 0.938183\n",
      "----\n",
      "eval mean loss: 0.125303\n",
      "eval accuracy: 0.948312\n",
      "eval avg class acc: 0.943158\n",
      "**** EPOCH 009 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.137692\n",
      "accuracy: 0.942134\n",
      "----\n",
      "eval mean loss: 0.167318\n",
      "eval accuracy: 0.927271\n",
      "eval avg class acc: 0.905507\n",
      "**** EPOCH 010 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.123655\n",
      "accuracy: 0.948877\n",
      "----\n",
      "eval mean loss: 0.142534\n",
      "eval accuracy: 0.936838\n",
      "eval avg class acc: 0.927010\n",
      "Model saved in file: log/model.ckpt\n",
      "**** EPOCH 011 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.124988\n",
      "accuracy: 0.947305\n",
      "----\n",
      "eval mean loss: 0.129025\n",
      "eval accuracy: 0.944010\n",
      "eval avg class acc: 0.933569\n",
      "**** EPOCH 012 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.116194\n",
      "accuracy: 0.951497\n",
      "----\n",
      "eval mean loss: 0.102787\n",
      "eval accuracy: 0.956480\n",
      "eval avg class acc: 0.939634\n",
      "**** EPOCH 013 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.109421\n",
      "accuracy: 0.954644\n",
      "----\n",
      "eval mean loss: 0.104907\n",
      "eval accuracy: 0.956615\n",
      "eval avg class acc: 0.943502\n",
      "**** EPOCH 014 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.107258\n",
      "accuracy: 0.955907\n",
      "----\n",
      "eval mean loss: 0.100656\n",
      "eval accuracy: 0.960815\n",
      "eval avg class acc: 0.951400\n",
      "**** EPOCH 015 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.098380\n",
      "accuracy: 0.959979\n",
      "----\n",
      "eval mean loss: 0.101990\n",
      "eval accuracy: 0.956859\n",
      "eval avg class acc: 0.948624\n",
      "**** EPOCH 016 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.097673\n",
      "accuracy: 0.959830\n",
      "----\n",
      "eval mean loss: 0.092650\n",
      "eval accuracy: 0.962902\n",
      "eval avg class acc: 0.940357\n",
      "**** EPOCH 017 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.091803\n",
      "accuracy: 0.962517\n",
      "----\n",
      "eval mean loss: 0.083726\n",
      "eval accuracy: 0.966089\n",
      "eval avg class acc: 0.956425\n",
      "**** EPOCH 018 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.092862\n",
      "accuracy: 0.962425\n",
      "----\n",
      "eval mean loss: 0.094968\n",
      "eval accuracy: 0.959409\n",
      "eval avg class acc: 0.948856\n",
      "**** EPOCH 019 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.088965\n",
      "accuracy: 0.963416\n",
      "----\n",
      "eval mean loss: 0.086884\n",
      "eval accuracy: 0.965018\n",
      "eval avg class acc: 0.960777\n",
      "**** EPOCH 020 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.087567\n",
      "accuracy: 0.964322\n",
      "----\n",
      "eval mean loss: 0.093732\n",
      "eval accuracy: 0.961898\n",
      "eval avg class acc: 0.948940\n",
      "Model saved in file: log/model.ckpt\n",
      "**** EPOCH 021 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.081134\n",
      "accuracy: 0.967741\n",
      "----\n",
      "eval mean loss: 0.084731\n",
      "eval accuracy: 0.965262\n",
      "eval avg class acc: 0.948225\n",
      "**** EPOCH 022 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.079676\n",
      "accuracy: 0.967977\n",
      "----\n",
      "eval mean loss: 0.077226\n",
      "eval accuracy: 0.967556\n",
      "eval avg class acc: 0.960849\n",
      "**** EPOCH 023 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.075094\n",
      "accuracy: 0.970025\n",
      "----\n",
      "eval mean loss: 0.092357\n",
      "eval accuracy: 0.964369\n",
      "eval avg class acc: 0.957083\n",
      "**** EPOCH 024 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.077980\n",
      "accuracy: 0.968526\n",
      "----\n",
      "eval mean loss: 0.105942\n",
      "eval accuracy: 0.956930\n",
      "eval avg class acc: 0.942468\n",
      "**** EPOCH 025 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.076987\n",
      "accuracy: 0.969217\n",
      "----\n",
      "eval mean loss: 0.080703\n",
      "eval accuracy: 0.969616\n",
      "eval avg class acc: 0.967237\n",
      "**** EPOCH 026 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.066907\n",
      "accuracy: 0.973372\n",
      "----\n",
      "eval mean loss: 0.079519\n",
      "eval accuracy: 0.968551\n",
      "eval avg class acc: 0.957081\n",
      "**** EPOCH 027 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.070965\n",
      "accuracy: 0.971660\n",
      "----\n",
      "eval mean loss: 0.087391\n",
      "eval accuracy: 0.963542\n",
      "eval avg class acc: 0.958972\n",
      "**** EPOCH 028 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.074079\n",
      "accuracy: 0.970507\n",
      "----\n",
      "eval mean loss: 0.089119\n",
      "eval accuracy: 0.965662\n",
      "eval avg class acc: 0.960055\n",
      "**** EPOCH 029 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.066912\n",
      "accuracy: 0.973464\n",
      "----\n",
      "eval mean loss: 0.077642\n",
      "eval accuracy: 0.968506\n",
      "eval avg class acc: 0.961293\n",
      "**** EPOCH 030 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.074313\n",
      "accuracy: 0.970448\n",
      "----\n",
      "eval mean loss: 0.076273\n",
      "eval accuracy: 0.969096\n",
      "eval avg class acc: 0.957559\n",
      "Model saved in file: log/model.ckpt\n",
      "**** EPOCH 031 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.065811\n",
      "accuracy: 0.973870\n",
      "----\n",
      "eval mean loss: 0.073859\n",
      "eval accuracy: 0.971162\n",
      "eval avg class acc: 0.965570\n",
      "**** EPOCH 032 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.060881\n",
      "accuracy: 0.976058\n",
      "----\n",
      "eval mean loss: 0.094929\n",
      "eval accuracy: 0.962038\n",
      "eval avg class acc: 0.952737\n",
      "**** EPOCH 033 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.060784\n",
      "accuracy: 0.976323\n",
      "----\n",
      "eval mean loss: 0.074825\n",
      "eval accuracy: 0.971478\n",
      "eval avg class acc: 0.965433\n",
      "**** EPOCH 034 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean loss: 0.064764\n",
      "accuracy: 0.974414\n",
      "----\n",
      "eval mean loss: 0.068725\n",
      "eval accuracy: 0.973061\n",
      "eval avg class acc: 0.967094\n",
      "**** EPOCH 035 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.060136\n",
      "accuracy: 0.976330\n",
      "----\n",
      "eval mean loss: 0.061819\n",
      "eval accuracy: 0.975444\n",
      "eval avg class acc: 0.971034\n",
      "**** EPOCH 036 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.056290\n",
      "accuracy: 0.978040\n",
      "----\n",
      "eval mean loss: 0.078202\n",
      "eval accuracy: 0.970583\n",
      "eval avg class acc: 0.960916\n",
      "**** EPOCH 037 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.060851\n",
      "accuracy: 0.975896\n",
      "----\n",
      "eval mean loss: 0.059115\n",
      "eval accuracy: 0.977329\n",
      "eval avg class acc: 0.967047\n",
      "**** EPOCH 038 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.051765\n",
      "accuracy: 0.979857\n",
      "----\n",
      "eval mean loss: 0.068604\n",
      "eval accuracy: 0.974162\n",
      "eval avg class acc: 0.966664\n",
      "**** EPOCH 039 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.053728\n",
      "accuracy: 0.978935\n",
      "----\n",
      "eval mean loss: 0.059638\n",
      "eval accuracy: 0.977195\n",
      "eval avg class acc: 0.969769\n",
      "**** EPOCH 040 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.056372\n",
      "accuracy: 0.978113\n",
      "----\n",
      "eval mean loss: 0.061199\n",
      "eval accuracy: 0.974919\n",
      "eval avg class acc: 0.968883\n",
      "Model saved in file: log/model.ckpt\n",
      "**** EPOCH 041 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.053041\n",
      "accuracy: 0.979188\n",
      "----\n",
      "eval mean loss: 0.062413\n",
      "eval accuracy: 0.975936\n",
      "eval avg class acc: 0.968155\n",
      "**** EPOCH 042 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.057964\n",
      "accuracy: 0.977600\n",
      "----\n",
      "eval mean loss: 0.053254\n",
      "eval accuracy: 0.979065\n",
      "eval avg class acc: 0.970118\n",
      "**** EPOCH 043 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.048649\n",
      "accuracy: 0.981250\n",
      "----\n",
      "eval mean loss: 0.077771\n",
      "eval accuracy: 0.969623\n",
      "eval avg class acc: 0.967626\n",
      "**** EPOCH 044 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.048923\n",
      "accuracy: 0.981019\n",
      "----\n",
      "eval mean loss: 0.085868\n",
      "eval accuracy: 0.966428\n",
      "eval avg class acc: 0.950020\n",
      "**** EPOCH 045 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.050204\n",
      "accuracy: 0.980681\n",
      "----\n",
      "eval mean loss: 0.063593\n",
      "eval accuracy: 0.974607\n",
      "eval avg class acc: 0.968454\n",
      "**** EPOCH 046 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.045370\n",
      "accuracy: 0.982634\n",
      "----\n",
      "eval mean loss: 0.056525\n",
      "eval accuracy: 0.978138\n",
      "eval avg class acc: 0.970043\n",
      "**** EPOCH 047 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.052436\n",
      "accuracy: 0.979954\n",
      "----\n",
      "eval mean loss: 0.060794\n",
      "eval accuracy: 0.976375\n",
      "eval avg class acc: 0.967059\n",
      "**** EPOCH 048 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.050316\n",
      "accuracy: 0.980358\n",
      "----\n",
      "eval mean loss: 0.063865\n",
      "eval accuracy: 0.975934\n",
      "eval avg class acc: 0.969048\n",
      "**** EPOCH 049 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.044835\n",
      "accuracy: 0.982709\n",
      "----\n",
      "eval mean loss: 0.064423\n",
      "eval accuracy: 0.975945\n",
      "eval avg class acc: 0.971452\n",
      "**** EPOCH 050 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.043197\n",
      "accuracy: 0.983297\n",
      "----\n",
      "eval mean loss: 0.072700\n",
      "eval accuracy: 0.975568\n",
      "eval avg class acc: 0.970716\n",
      "Model saved in file: log/model.ckpt\n",
      "**** EPOCH 051 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.044660\n",
      "accuracy: 0.983037\n",
      "----\n",
      "eval mean loss: 0.059537\n",
      "eval accuracy: 0.977720\n",
      "eval avg class acc: 0.975635\n",
      "**** EPOCH 052 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.045764\n",
      "accuracy: 0.982061\n",
      "----\n",
      "eval mean loss: 0.074641\n",
      "eval accuracy: 0.973178\n",
      "eval avg class acc: 0.976110\n",
      "**** EPOCH 053 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.042823\n",
      "accuracy: 0.983557\n",
      "----\n",
      "eval mean loss: 0.070940\n",
      "eval accuracy: 0.973927\n",
      "eval avg class acc: 0.959471\n",
      "**** EPOCH 054 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.043056\n",
      "accuracy: 0.983445\n",
      "----\n",
      "eval mean loss: 0.063611\n",
      "eval accuracy: 0.976739\n",
      "eval avg class acc: 0.965358\n",
      "**** EPOCH 055 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.040576\n",
      "accuracy: 0.984486\n",
      "----\n",
      "eval mean loss: 0.056141\n",
      "eval accuracy: 0.979802\n",
      "eval avg class acc: 0.974514\n",
      "**** EPOCH 056 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.040364\n",
      "accuracy: 0.984601\n",
      "----\n",
      "eval mean loss: 0.057120\n",
      "eval accuracy: 0.979442\n",
      "eval avg class acc: 0.977449\n",
      "**** EPOCH 057 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.037875\n",
      "accuracy: 0.985485\n",
      "----\n",
      "eval mean loss: 0.052836\n",
      "eval accuracy: 0.980550\n",
      "eval avg class acc: 0.975055\n",
      "**** EPOCH 058 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.037842\n",
      "accuracy: 0.985753\n",
      "----\n",
      "eval mean loss: 0.053704\n",
      "eval accuracy: 0.980324\n",
      "eval avg class acc: 0.976397\n",
      "**** EPOCH 059 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.042987\n",
      "accuracy: 0.983429\n",
      "----\n",
      "eval mean loss: 0.059014\n",
      "eval accuracy: 0.977225\n",
      "eval avg class acc: 0.973923\n",
      "**** EPOCH 060 ****\n",
      "----\n",
      "Current batch/total batch num: 0/86\n",
      "mean loss: 0.041227\n",
      "accuracy: 0.984148\n",
      "----\n",
      "eval mean loss: 0.083615\n",
      "eval accuracy: 0.970554\n",
      "eval avg class acc: 0.964113\n",
      "Model saved in file: log/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def log_string(out_str):\n",
    "    LOG_FOUT.write(out_str+'\\n')\n",
    "    LOG_FOUT.flush()\n",
    "    print(out_str)\n",
    "\n",
    "\n",
    "def get_learning_rate(batch):\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "                        BASE_LEARNING_RATE,  # Base learning rate.\n",
    "                        batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "                        DECAY_STEP,          # Decay step.\n",
    "                        DECAY_RATE,          # Decay rate.\n",
    "                        staircase=True)\n",
    "    learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!!\n",
    "    return learning_rate        \n",
    "\n",
    "def get_bn_decay(batch):\n",
    "    bn_momentum = tf.train.exponential_decay(\n",
    "                      BN_INIT_DECAY,\n",
    "                      batch*BATCH_SIZE,\n",
    "                      BN_DECAY_DECAY_STEP,\n",
    "                      BN_DECAY_DECAY_RATE,\n",
    "                      staircase=True)\n",
    "    bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n",
    "    return bn_decay\n",
    "\n",
    "def train():\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.device('/gpu:'+str(GPU_INDEX)):\n",
    "            pointclouds_pl, labels_pl = placeholder_inputs(BATCH_SIZE, NUM_POINT)\n",
    "            is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "            \n",
    "            # Note the global_step=batch parameter to minimize. \n",
    "            # That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.\n",
    "            batch = tf.Variable(0)\n",
    "            bn_decay = get_bn_decay(batch)\n",
    "            tf.summary.scalar('bn_decay', bn_decay)\n",
    "\n",
    "            # Get model and loss \n",
    "            pred = get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay)\n",
    "            loss = get_loss(pred, labels_pl)\n",
    "            tf.summary.scalar('loss', loss)\n",
    "\n",
    "            correct = tf.equal(tf.argmax(pred, 2), tf.to_int64(labels_pl))\n",
    "            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE*NUM_POINT)\n",
    "            tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "            # Get training operator\n",
    "            learning_rate = get_learning_rate(batch)\n",
    "            tf.summary.scalar('learning_rate', learning_rate)\n",
    "            if OPTIMIZER == 'momentum':\n",
    "                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n",
    "            elif OPTIMIZER == 'adam':\n",
    "                optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            train_op = optimizer.minimize(loss, global_step=batch)\n",
    "            \n",
    "            # Add ops to save and restore all the variables.\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "        # Create a session\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        config.allow_soft_placement = True\n",
    "        config.log_device_placement = True\n",
    "        sess = tf.Session(config=config)\n",
    "\n",
    "        # Add summary writers\n",
    "        merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'train'),\n",
    "                                  sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'test'))\n",
    "\n",
    "        # Init variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init, {is_training_pl:True})\n",
    "\n",
    "        ops = {'pointclouds_pl': pointclouds_pl,\n",
    "               'labels_pl': labels_pl,\n",
    "               'is_training_pl': is_training_pl,\n",
    "               'pred': pred,\n",
    "               'loss': loss,\n",
    "               'train_op': train_op,\n",
    "               'merged': merged,\n",
    "               'step': batch}\n",
    "\n",
    "        for epoch in range(MAX_EPOCH):\n",
    "            log_string('**** EPOCH %03d ****' % (epoch))\n",
    "            sys.stdout.flush()\n",
    "             \n",
    "            train_one_epoch(sess, ops, train_writer)\n",
    "            eval_one_epoch(sess, ops, test_writer)\n",
    "            \n",
    "            # Save the variables to disk.\n",
    "            if epoch % 10 == 0:\n",
    "                save_path = saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"))\n",
    "                log_string(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(sess, ops, train_writer):\n",
    "    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n",
    "    is_training = True\n",
    "    \n",
    "    log_string('----')\n",
    "    current_data, current_label, _ = provider.shuffle_data(train_data[:,0:NUM_POINT,:], train_label) \n",
    "    \n",
    "    file_size = current_data.shape[0]\n",
    "    num_batches = file_size // BATCH_SIZE\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_seen = 0\n",
    "    loss_sum = 0\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Current batch/total batch num: %d/%d'%(batch_idx,num_batches))\n",
    "        start_idx = batch_idx * BATCH_SIZE\n",
    "        end_idx = (batch_idx+1) * BATCH_SIZE\n",
    "        \n",
    "        feed_dict = {ops['pointclouds_pl']: current_data[start_idx:end_idx, :, :],\n",
    "                     ops['labels_pl']: current_label[start_idx:end_idx],\n",
    "                     ops['is_training_pl']: is_training,}\n",
    "        summary, step, _, loss_val, pred_val = sess.run([ops['merged'], ops['step'], ops['train_op'], ops['loss'], ops['pred']],\n",
    "                                         feed_dict=feed_dict)\n",
    "        train_writer.add_summary(summary, step)\n",
    "        pred_val = np.argmax(pred_val, 2)\n",
    "        correct = np.sum(pred_val == current_label[start_idx:end_idx])\n",
    "        total_correct += correct\n",
    "        total_seen += (BATCH_SIZE*NUM_POINT)\n",
    "        loss_sum += loss_val\n",
    "    \n",
    "    log_string('mean loss: %f' % (loss_sum / float(num_batches)))\n",
    "    log_string('accuracy: %f' % (total_correct / float(total_seen)))\n",
    "\n",
    "        \n",
    "def eval_one_epoch(sess, ops, test_writer):\n",
    "    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n",
    "    is_training = False\n",
    "    total_correct = 0\n",
    "    total_seen = 0\n",
    "    loss_sum = 0\n",
    "    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
    "    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "    \n",
    "    log_string('----')\n",
    "    current_data = test_data[:,0:NUM_POINT,:]\n",
    "    current_label = np.squeeze(test_label)\n",
    "    \n",
    "    file_size = current_data.shape[0]\n",
    "    num_batches = file_size // BATCH_SIZE_EVAL\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * BATCH_SIZE_EVAL\n",
    "        end_idx = (batch_idx+1) * BATCH_SIZE_EVAL\n",
    "\n",
    "        feed_dict = {ops['pointclouds_pl']: current_data[start_idx:end_idx, :, :],\n",
    "                     ops['labels_pl']: current_label[start_idx:end_idx],\n",
    "                     ops['is_training_pl']: is_training}\n",
    "        summary, step, loss_val, pred_val = sess.run([ops['merged'], ops['step'], ops['loss'], ops['pred']],\n",
    "                                      feed_dict=feed_dict)\n",
    "        test_writer.add_summary(summary, step)\n",
    "        pred_val = np.argmax(pred_val, 2)\n",
    "        correct = np.sum(pred_val == current_label[start_idx:end_idx])\n",
    "        total_correct += correct\n",
    "        total_seen += (BATCH_SIZE_EVAL*NUM_POINT)\n",
    "        loss_sum += (loss_val*BATCH_SIZE_EVAL)\n",
    "        for i in range(start_idx, end_idx):\n",
    "            for j in range(NUM_POINT):\n",
    "                l = int(current_label[i, j])\n",
    "                total_seen_class[l] += 1\n",
    "                total_correct_class[l] += (pred_val[i-start_idx, j] == l)\n",
    "            \n",
    "    log_string('eval mean loss: %f' % (loss_sum / float(total_seen/NUM_POINT)))\n",
    "    log_string('eval accuracy: %f'% (total_correct / float(total_seen)))\n",
    "    log_string('eval avg class acc: %f' % (np.mean(np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float))))\n",
    "         \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n",
    "    LOG_FOUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
